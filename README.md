# An√°lise e Previs√£o de Sobreviventes do Titanic com KNN

Este reposit√≥rio cont√©m um notebook em Python que demonstra um fluxo de trabalho completo de Machine Learning para prever a sobreviv√™ncia de passageiros do Titanic, utilizando o algoritmo K-Nearest Neighbors (KNN).

## üö¢ Sobre o Projeto

O objetivo principal √© aplicar t√©cnicas de pr√©-processamento de dados em um dataset real e, em seguida, treinar e avaliar um modelo de classifica√ß√£o KNN. O notebook √© estruturado de forma did√°tica, ideal para fins de estudo e demonstra√ß√£o de conceitos fundamentais em ci√™ncia de dados.

## üöÄ Como Executar o Notebook

Para que o c√≥digo funcione corretamente, √© necess√°rio que o arquivo `train.csv` esteja no mesmo ambiente de execu√ß√£o do notebook.

1.  **Fa√ßa o download dos arquivos:** Clone ou baixe este reposit√≥rio para a sua m√°quina.

2.  **Carregue o dataset:**
    * **Se estiver usando o Google Colab:**
        1.  No painel √† esquerda, clique no √≠cone de pasta (Arquivos).
        2.  Clique no bot√£o "Fazer upload para o armazenamento da sess√£o".
        3.  Selecione o arquivo `train.csv` que voc√™ baixou.
        4.  Aguarde o upload ser conclu√≠do. O arquivo aparecer√° no painel.

    * **Se estiver usando Jupyter Notebook (localmente):**
        1.  Certifique-se de que o arquivo `train.csv` est√° na mesma pasta onde voc√™ salvou o notebook (`.ipynb`).

3.  **Execute o c√≥digo:** Com o arquivo no lugar certo, basta executar as c√©lulas do notebook em ordem.

### üìä Metodologia

O processo abordado no c√≥digo segue as seguintes etapas:

1.  **An√°lise Explorat√≥ria e Entendimento dos Dados:** Carregamento do dataset e investiga√ß√£o inicial das colunas e tipos de dados.
2.  **Pr√©-processamento de Dados:**
    * **Limpeza:** Exclus√£o de colunas irrelevantes (`id`, `nome`, `bilhete`) e da coluna `cabine` por excesso de valores ausentes.
    * **Tratamento de Dados Faltantes:** Remo√ß√£o de linhas com valores nulos (`dropna`).
    * **Transforma√ß√£o de Dados Categ√≥ricos:** Aplica√ß√£o de One-Hot Encoding nas colunas `classe_social`, `sexo` e `embarque` com `pd.get_dummies`.
    * **Normaliza√ß√£o de Dados Num√©ricos:** As colunas cont√≠nuas (`idade`, `parentes`, `dependentes`, `tarifa`) s√£o normalizadas (escala de 0 a 1), uma vez que o teste de normalidade de Shapiro-Wilk indicou que n√£o seguem uma distribui√ß√£o normal.
3.  **Modelagem com KNN:**
    * Implementa√ß√£o da dist√¢ncia euclidiana como base para o algoritmo.
    * Divis√£o do dataset em conjuntos de treino e teste (`train_test_split`).
    * Treinamento do classificador `KNeighborsClassifier`.
    * Busca por um valor ideal de `k` (vizinhos) para otimizar a performance.
4.  **Avalia√ß√£o do Modelo:**
    * Realiza√ß√£o de previs√µes no conjunto de teste.
    * C√°lculo da acur√°cia do modelo para medir seu desempenho.

### üõ†Ô∏è Bibliotecas Utilizadas

* **Pandas:** Para manipula√ß√£o e an√°lise de dados.
* **NumPy:** Para opera√ß√µes num√©ricas.
* **Scikit-learn:** Para a divis√£o dos dados, implementa√ß√£o do KNN e avalia√ß√£o de m√©tricas.
* **SciPy:** Para a realiza√ß√£o do teste de normalidade de Shapiro-Wilk.
* **Seaborn:** Para visualiza√ß√£o de dados.
