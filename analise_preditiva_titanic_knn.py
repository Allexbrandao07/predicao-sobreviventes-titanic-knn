# -*- coding: utf-8 -*-
"""Aula04_KNN_Titanic_com_pré_processamento.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rPcej98IfC3rl8BBisbecAg4mOpm6XpT

**Importando as bibliotecas**
"""

import pandas as pd
import numpy as np

"""**Criando as funções para tratar dados numéricos contínuos**"""

def normalizar(x): #x será uma lista de valores numéricos
  return (x - np.min(x))/(np.max(x) - np.min(x))

def padronizar(x):
  return (x -np.mean(x))/np.std(x)

"""**Carregando o dataframe**"""

df = pd.read_csv("train.csv")
df.head(10)

"""**Excluindo as colunas irrelevantes**"""

df = df.drop(columns=['id', 'nome', 'bilhete'])
df

"""# **Entendendo os dados**"""

df.sexo.unique()

df.classe_social.unique()

df.idade.unique()

df.columns

for coluna in df.columns:
  print(f"{coluna}: {df[coluna].unique()}")
  print("-------------------------------------------------------")

df.info()

df.isna().sum()

687/891

df.shape

177/891

"""# **Tratando os dados**

**Removendo colunas**
"""

df = df.drop('cabine', axis=1)
#df.drop('cabine', inplace=True)
#df = df.drop(columns=['cabine'])
#df = df[['sobreviveu',	'classe_social',	'sexo',	'idade','parentes',	'dependentes',	'tarifa',	'embarque']]
df.head(50)

"""**Apagando dados Not A Number**"""

df = df.dropna()
df

df.isna().sum()

df.shape

"""# **Tratando dados numéricos contínuos**"""

import seaborn as sb
sb.pairplot(df[['idade',	'parentes',	'dependentes'	,'tarifa', 'sobreviveu']], hue='sobreviveu')

"""**Função para verificar se os dados seguem uma distribuição normal**"""

from scipy.stats import shapiro
# Verificar normalidade usando o teste de Shapiro-Wilk
def verifica_normalidade(dataframe, coluna):
    coluna_data = dataframe[coluna]
    # Realizar o teste de Shapiro-Wilk
    statistic, p_valor = shapiro(coluna_data)
    # Definir o nível de significância
    nivel_significancia = 0.05
    # Verificar se a hipótese nula de normalidade pode ser rejeitada
    if p_valor > nivel_significancia:
        print(f"A coluna '{coluna}' segue uma distribuição normal")
        return True
    else:
        print(f"A coluna '{coluna}' não segue uma distribuição normal")
        return False

"""**Aplicando padronização ou normalização**"""

# Chamando a função para verificar normalidade
for coluna in ['idade',	'parentes',	'dependentes',	'tarifa'	]:
  if verifica_normalidade(df, coluna):
    df[coluna] = padronizar(df[coluna])#se for distribuição normal, padroniza

  else:#senão, normaliza
    df[coluna] = normalizar(df[coluna])

#for coluna in ['idade',	'parentes',	'dependentes',	'tarifa'	]:
#  df[coluna] = normalizar(df[coluna])

df

"""# **Tratando dados categóricos**"""

df = pd.get_dummies(df, columns=['classe_social', 'sexo',  'embarque'])
df

"""# **KNN**"""

def distancia_euclidiana(A, B):
  if len(A) != len(B):
    print("ERRO de dimensões.")
    return 0

  total = 0
  for i in range(0, len(A)):
    total += (B[i] - A[i])**2

  return total**0.5

pontoA = [6, 3, 200, 1795, -50]
pontoB = [12, -7, 2, 355, -9]

distancia_euclidiana(pontoA, pontoB)

df.head(1)

from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

y = df['sobreviveu']#classe (saída)
X = df.drop('sobreviveu', axis=1) #entradas

# Dividir o conjunto de dados em treino e teste
X_train, X_test, y_train, y_test = train_test_split(X, y,
                                                    test_size=0.3,
                                                    random_state=42)

X.shape[0]**0.5

knn = KNeighborsClassifier(n_neighbors=27)

# Treinar o modelo kNN
knn.fit(X_train, y_train)

y_pred = knn.predict(X_test)

# Avaliar a acurácia do modelo
accuracy = accuracy_score(y_test, y_pred)
print("Acurácia do modelo kNN:", accuracy)

X_test

print("n=",len(y))
print("k=", (len(y))**0.5)

#testando o k ideal
for k in range(3, 51, 2):
  knn = KNeighborsClassifier(n_neighbors=k)
  # Treinar o modelo kNN
  knn.fit(X_train, y_train)
  y_pred = knn.predict(X_test)

  # Avaliar a acurácia do modelo
  accuracy = accuracy_score(y_test, y_pred)
  print(f"Acurácia para k={k}:", accuracy)

# Selecionar o primeiro exemplo do conjunto de teste
exemplo = X_test.iloc[[22]]
saida_real = y_test.iloc[22]

# Fazer a previsão com o modelo treinado
previsao = knn.predict(exemplo)

# Imprimir a previsão e a saída real
print("Previsão:", previsao[0])
print("Saída Real:", saida_real)

# Fazer previsões para todo o conjunto de teste
previsoes = knn.predict(X_test)

# Criar um DataFrame para comparar as previsões com as saídas reais
comparacao = pd.DataFrame({'Previsão': previsoes, 'Saída Real': y_test})

# Mostrar o DataFrame de comparação
comparacao
